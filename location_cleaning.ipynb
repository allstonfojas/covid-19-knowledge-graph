{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Cleaning Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braden Riggs A15089134 DSC198\n",
    "\n",
    "Additional geodata provided by Geonames.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages for cleaning\n",
    "#!pip install pycountry\n",
    "#!pip install geopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycountry\n",
    "from geopy.geocoders import Nominatim\n",
    "pd.options.display.max_columns = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter file for standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_file = \"data/CNCB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter location column names(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = \"Location\"\n",
    "loc2 = \"none\"\n",
    "loc3 = \"none\"\n",
    "loc4 = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Below Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_url = \"https://bigd.big.ac.cn/ncov/genome/export/meta\"\n",
    "df = pd.read_excel(metadata_url, dtype='str')\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA AS DF\n",
    "#df = pd.read_csv(std_file)\n",
    "#df = df[:100] #For testing\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #1 Geocode initial location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row filtering and organizing data\n",
    "def order_geocode(datafrm, loc1, loc2=\"none\", loc3=\"none\", loc4=\"none\"):\n",
    "    if isinstance(datafrm, pd.DataFrame):\n",
    "        if loc2 != \"none\" and loc2 not in list(datafrm.columns):\n",
    "            print(\"Error loc2 is an invalid column name!\")\n",
    "        if loc3 != \"none\" and loc3 not in list(datafrm.columns):\n",
    "            print(\"Error loc3 is an invalid column name!\")\n",
    "        if loc4 != \"none\" and loc4 not in list(datafrm.columns):\n",
    "            print(\"Error loc4 is an invalid column name!\")\n",
    "        \n",
    "        \n",
    "        if loc1 in list(datafrm.columns):\n",
    "            datafrm[\"location_series\"] = datafrm[loc1]\n",
    "            if loc2 != \"none\":\n",
    "                datafrm[\"location_series\"] = datafrm.location_series.map(str) + \", \" + datafrm[\"loc2\"].map(str)\n",
    "            if loc3 != \"none\":\n",
    "                datafrm[\"location_series\"] = datafrm.location_series.map(str) + \", \" + datafrm[\"loc3\"].map(str)\n",
    "            if loc4 != \"none\":\n",
    "                datafrm[\"location_series\"] = datafrm.location_series.map(str) + \", \" + datafrm[\"loc4\"].map(str)\n",
    "                \n",
    "            grouped_loc = datafrm.groupby(\"location_series\").count()\n",
    "            \n",
    "            holder1 = []\n",
    "            c = 0\n",
    "            for i in grouped_loc.index:\n",
    "                temp = str(do_geocode(text_cleaner(i)))\n",
    "                print(str(c) + \", \", end = '')\n",
    "                temp = temp.split(\",\")\n",
    "                holder2 = []\n",
    "                for k in temp:\n",
    "                    holder2.insert(0,text_cleaner(k))\n",
    "                holder1.append(holder2)\n",
    "                c = c + 1\n",
    "            print(grouped_loc.shape)\n",
    "            locs = pd.DataFrame(holder1, columns = [\"Country\",\"Zip_Code\",\"Admin1\",\"Admin2\",\"Admin3\",\"Admin4\",\"Admin5\",\"Admin6\",\"Admin7\",\"Admin8\", \"Admin9\",\"Admin10\"])\n",
    "            print(locs.shape)\n",
    "            locs[\"location_series\"] = grouped_loc.index\n",
    "                \n",
    "            return locs\n",
    "                \n",
    "        else:\n",
    "            print(\"Loc1 must be a valid column name!\")\n",
    "    else:\n",
    "        print(\"Datafrm must be a pandas dataframe type object!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"covid19_geocoding\")\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "\n",
    "#Geocodes\n",
    "def do_geocode(address):\n",
    "    try:\n",
    "        return geolocator.geocode(address,addressdetails=True, geometry='wkt', extratags=True, timeout = 5, language = \"en-US\")\n",
    "    except GeocoderTimedOut:\n",
    "        return do_geocode(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = str(text).lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\"-\",\" \")\n",
    "    text = text.replace(\",\",\" \")\n",
    "    text = text.replace(\"!\",\"\")\n",
    "    text = text.replace(\"ä\",\"a\")\n",
    "    text = text.replace(\"ó\",\"o\")\n",
    "    text = text.replace(\"è\",\"e\")\n",
    "    text = text.replace(\":\",\",\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = order_geocode(df,loc1)\n",
    "df = pd.merge(df, temp, how='inner',left_on=\"location_series\", right_on=\"location_series\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(std_file + \"_GeoCoded\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #2 Match on Geonames Data for Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load back in saved data\n",
    "df = pd.read_csv(std_file + \"_GeoCoded\",  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv(\"data/countryInfo.txt\", sep='\\t', skiprows=(np.arange(49))) #Skip metadata\n",
    "countries = countries[[\"Country\",\"#ISO\",\"ISO3\",\"ISO-Numeric\",\"fips\",\"geonameid\",\"neighbours\"]] #Filter for relevent data\n",
    "countries = countries.rename(columns = {\"neighbours\" : \"Neighbouring_Country\"})\n",
    "countries[\"Country\"] = countries[\"Country\"].str.lower()\n",
    "countries.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None type entry\n",
    "noner = pd.Series([\"none\",\"None\",\"None\",\"None\",\"None\",\"None\",\"None\"], index = [\"Country\",\"#ISO\",\"ISO3\",\"ISO-Numeric\",\"fips\",\"geonameid\",\"Neighbouring_Country\"])\n",
    "\n",
    "\n",
    "countries[\"Country\"] = countries[\"Country\"].replace({\"czechia\":\"czech republic\", \"united states\":\"united states of america\",\"netherlands\":\"the netherlands\"})\n",
    "df[\"Country\"] = df[\"Country\"].replace({\"united states\":\"united states of america\",\"czechia\":\"czech republic\",\"netherlands\":\"the netherlands\"})\n",
    "countries = countries.append(noner, ignore_index = True)\n",
    "\n",
    "\n",
    "hold= []\n",
    "for i in df[\"Country\"].unique():\n",
    "    temp = 0\n",
    "    for j in countries[\"Country\"].unique():\n",
    "        if i == j:\n",
    "            hold.append(i)\n",
    "            temp = 1\n",
    "            break\n",
    "    if temp != 1: #USA is called united states and Czech Republic is called Czechia\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df_country = pd.merge(df, countries, how='inner',left_on=\"Country\", right_on=\"Country\")\n",
    "df_country\n",
    "print(df_country.shape) #Evaluating loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country.to_csv(std_file + \"_GeoNamed\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #3 Match on Geonames Data for Admin 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_df = pd.read_csv(std_file + \"_GeoCoded\")\n",
    "geodata_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
